{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scrapping the web in Python using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we need to retireve data from an url in web and use it for our analysis.But as you know URL is nothing but a HTML page and it is nothing but the unstructured data.It also has many tags such as div,table,td,href etc. In general to turn html into useful data you need to parse it and extract structured data from it. This is called as <u>_'Web Scrapping'_</u>. Such tasks can be accomplished by using a python library called **Beautiful Soup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to first retrieve the unstructured data from a html page and then use Beautiful Soup to parse it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieving data from an URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we will use requests package to do this\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#specify the url\n",
    "url = 'https://www.learnpython.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pass the url to get function which retrievs the data from web\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save html response as a string\n",
    "html_doc = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Beautiful Soup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you need to install Beautiful Soup by writing following command in command prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import necessary functon from Beautiful Soup\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create beautiful soup object from html string\n",
    "soup = BeautifulSoup(html_doc,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use the method prettify() on soup\n",
    "pretty_soup = soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This created simplified html and we can use various methods on it. One such method is title() to get the title of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Learn Python - Free Interactive Python Tutorial</title>\n"
     ]
    }
   ],
   "source": [
    "#print title of the page by using title() method\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will be showing you how you can extract url of all the hyperlinks used in the html page.\n",
    "For this we will be using soup method find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all 'a' tags (which define hyperlinks)\n",
    "a_tags = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to enumerate over it using a for loop and print the actual URLs of hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "bitcoin:1PdKc2wAZoGq4kkCQ9Engig9x3TspCeVa8\n",
      "/about\n",
      "https://www.learnpython.org\n",
      "https://www.learnjavaonline.org\n",
      "https://www.learn-html.org\n",
      "https://www.learn-golang.org\n",
      "https://www.learn-c.org\n",
      "https://www.learn-cpp.org\n",
      "https://www.learn-js.org\n",
      "https://www.learn-php.org\n",
      "https://www.learnshell.org\n",
      "https://www.learncs.org\n",
      "https://www.learn-perl.org\n",
      "https://www.learnrubyonline.org\n",
      "/recruit-coders-jobs\n",
      "/en/\n",
      "/es/\n",
      "/fa/\n",
      "/fr/\n",
      "/it/\n",
      "/pl/\n",
      "/pt/\n",
      "https://www.datacamp.com/?utm_source=learnpython_com&utm_campaign=learnpython_tutorials\n",
      "https://www.datacamp.com/courses/?utm_source=learnpython_com&utm_campaign=learnpython_tutorials\n",
      "http://www.facebook.com/groups/180708015327157/\n",
      "/en/Hello%2C_World%21\n",
      "/en/Variables_and_Types\n",
      "/en/Lists\n",
      "/en/Basic_Operators\n",
      "/en/String_Formatting\n",
      "/en/Basic_String_Operations\n",
      "/en/Conditions\n",
      "/en/Loops\n",
      "/en/Functions\n",
      "/en/Classes_and_Objects\n",
      "/en/Dictionaries\n",
      "/en/Modules_and_Packages\n",
      "/en/Numpy_Arrays\n",
      "/en/Pandas_Basics\n",
      "/en/Generators\n",
      "/en/List_Comprehensions\n",
      "/en/Multiple_Function_Arguments\n",
      "/en/Regular_Expressions\n",
      "/en/Exception_Handling\n",
      "/en/Sets\n",
      "/en/Serialization\n",
      "/en/Partial_functions\n",
      "/en/Code_Introspection\n",
      "/en/Closures\n",
      "/en/Decorators\n",
      "https://www.datacamp.com/?utm_source=learnpython_com&utm_campaign=learnpython_tutorials\n",
      "https://www.datacamp.com/courses/?utm_source=learnpython_com&utm_campaign=learnpython_tutorials\n",
      "http://www.afterhoursprogramming.com/index.php?article=181\n",
      "/en/Contributing_Tutorials\n",
      "https://click.linksynergy.com/link?id=2mhs2G02AJA&offerid=358574.426570&type=2&murl=https%3A%2F%2Fwww.udemy.com%2Flearn-python%2F\n",
      "https://digitalocean.com/\n",
      "/tos\n",
      "/privacy\n"
     ]
    }
   ],
   "source": [
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this way you can use other methods to extract meaningfull data from an URL and use it in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook BeautifulSoup.ipynb to HTML\n",
      "[NbConvertApp] Writing 260694 bytes to BeautifulSoup.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to HTML BeautifulSoup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook BeautifulSoup.ipynb to PDF\n",
      "[NbConvertApp] Writing 25638 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\Scripts\\jupyter-nbconvert-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\jupyter_core\\application.py\", line 267, in launch_instance\n",
      "    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 325, in start\n",
      "    self.convert_notebooks()\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 493, in convert_notebooks\n",
      "    self.convert_single_notebook(notebook_filename)\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 464, in convert_single_notebook\n",
      "    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 393, in export_single_notebook\n",
      "    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\exporters\\exporter.py\", line 174, in from_filename\n",
      "    return self.from_file(f, resources=resources, **kw)\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\exporters\\exporter.py\", line 192, in from_file\n",
      "    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\exporters\\pdf.py\", line 175, in from_notebook_node\n",
      "    rc = self.run_latex(tex_file)\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\exporters\\pdf.py\", line 137, in run_latex\n",
      "    self.latex_count, log_error)\n",
      "  File \"C:\\Users\\Shweta\\Anaconda3\\lib\\site-packages\\nbconvert\\exporters\\pdf.py\", line 99, in run_command\n",
      "    \"at {link}.\".format(formatter=command_list[0], link=link))\n",
      "OSError: xelatex not found on PATH, if you have not installed xelatex you may need to do so. Find further instructions at https://nbconvert.readthedocs.io/en/latest/install.html#installing-tex.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to PDF BeautifulSoup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ({'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\Shweta\\\\AppData\\\\Roaming', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'DESKTOP-FL6M1PR', 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe', 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer', 'FPS_BROWSER_USER_PROFILE_STRING': 'Default', 'FSHARPINSTALLDIR': 'C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\F#\\\\4.1\\\\Framework\\\\v4.0\\\\', 'HADOOP_HOME': 'C:\\\\opt\\\\spark\\\\spark-2.2.0-bin-hadoop2.7', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\Shweta', 'LOCALAPPDATA': 'C:\\\\Users\\\\Shweta\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\DESKTOP-FL6M1PR', 'MSMPI_BIN': 'C:\\\\Program Files\\\\Microsoft MPI\\\\Bin\\\\', 'NUMBER_OF_PROCESSORS': '4', 'ONEDRIVE': 'C:\\\\Users\\\\Shweta\\\\OneDrive', 'OS': 'Windows_NT', 'PATH': 'C:\\\\Users\\\\Shweta\\\\Anaconda3;C:\\\\Users\\\\Shweta\\\\Anaconda3\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\Shweta\\\\Anaconda3\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\Shweta\\\\Anaconda3\\\\Library\\\\bin;C:\\\\Users\\\\Shweta\\\\Anaconda3\\\\Scripts;C:\\\\Users\\\\Shweta\\\\Anaconda3\\\\Library\\\\bin;C:\\\\ProgramData\\\\Oracle\\\\Java\\\\javapath;C:\\\\Program Files\\\\Microsoft MPI\\\\Bin\\\\;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Program Files\\\\dotnet\\\\;C:\\\\Program Files\\\\Microsoft SQL Server\\\\130\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\;C:\\\\Program Files\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\DTS\\\\Binn\\\\;C:\\\\Program Files\\\\Microsoft SQL Server\\\\140\\\\DTS\\\\Binn\\\\;C:\\\\Program Files\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\130\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\130\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\ManagementStudio\\\\;C:\\\\Program Files (x86)\\\\Gow\\\\bin;C:\\\\opt\\\\spark\\\\spark-2.2.0-bin-hadoop2.7\\\\bin;C:\\\\Users\\\\Shweta\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 58 Stepping 9, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': '3a09', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules;C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules\\\\;C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\Azure\\\\PowerShell\\\\ResourceManager\\\\AzureResourceManager\\\\;C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\Azure\\\\PowerShell\\\\ServiceManagement\\\\;C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\Azure\\\\PowerShell\\\\Storage\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\PowerShell\\\\Modules\\\\', 'PUBLIC': 'C:\\\\Users\\\\Public', 'PYSPARK_DRIVER_PYTHON': 'jupyter', 'PYSPARK_DRIVER_PYTHON_OPTS': 'notebook', 'SESSIONNAME': 'Console', 'SPARK_HOME': 'C:\\\\opt\\\\spark\\\\spark-2.2.0-bin-hadoop2.7', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\WINDOWS', 'TEMP': 'C:\\\\Users\\\\Shweta\\\\AppData\\\\Local\\\\Temp', 'TMP': 'C:\\\\Users\\\\Shweta\\\\AppData\\\\Local\\\\Temp', 'USERDOMAIN': 'DESKTOP-FL6M1PR', 'USERDOMAIN_ROAMINGPROFILE': 'DESKTOP-FL6M1PR', 'USERNAME': 'Shweta', 'USERPROFILE': 'C:\\\\Users\\\\Shweta', 'WINDIR': 'C:\\\\WINDOWS', 'CONDA_PREFIX': 'C:\\\\Users\\\\Shweta\\\\Anaconda3', 'JPY_INTERRUPT_EVENT': '884', 'IPY_INTERRUPT_EVENT': '884', 'JPY_PARENT_PID': '1328', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
