{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data from various file types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a data scientists work with data, the source of the data need not be only one. There are number of file types form where we need to extract the data. In this article we will see how to import data from following file types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Excel spreadsheets\n",
    "- SAS files\n",
    "- Stata files\n",
    "- HDF5 fils\n",
    "- MATLAB files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel spreadsheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of excel file is so widespread that it needs no introduction. Generally, an excel file consists of number of sheets. There are many ways to import excel file. We will use pandas to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import package pandas\n",
    "import pandas as pd\n",
    "\n",
    "#assign file name to a string variable\n",
    "file = 'battledeath.xlsx'\n",
    "\n",
    "#call pandas function to rad this excel file\n",
    "data = pd.ExcelFile(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often an excel file may have various sheets. We can check out how many sheets an excel has by following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2002', '2004']\n"
     ]
    }
   ],
   "source": [
    "print(data.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load data from perticular sheet we need to use .parse() function by passing the sheet name or sheet index. Pandas is clever enough to understand you are passing a sheetname or an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = data.parse(\"2002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = data.parse(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAS or Stata files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAS is an acronym for * \"Statistical Analysis System\" * where as Stata is contraction of *\"Statistics\"* and *\"Data\"*. The former is used in business analytics and biostatistics while the later is popular in academic social sciences research such as Economics and Epidemiology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAS files are important because SAS is a software suit that performs following steps.\n",
    "- Advance analytics\n",
    "- Multivariate analysis\n",
    "- Business intelligence\n",
    "- Data Management\n",
    "- Predictive analytics\n",
    "- Standard for computational analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common file extention for SAS files are **.sas7bdat** or **.sas7bcat** which are dataset files and categorical files respectively. The former files can be imported as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "with SAS7BDAT('sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stata files have extention **.dta** and we can import them using pandas as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_stata('disarea.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 stands for *\"Hierarchical Data Format version 5\"*. This is a standard mechanism for storing large quantities of numerical data. Now how large are we talking ? It is relatively common to deal with datasets which can be hundreds of gigabytes or terabytes. HDF5 itself can scale to exabytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import package h5py to extract data from such files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File('L-L1_LOSC_4_V1-1126259446-32.hdf5','r')  # 'r' is to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.files.File'>\n"
     ]
    }
   ],
   "source": [
    "#check the type of variable 'data'\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The structure of HDF5 files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta\n",
      "quality\n",
      "strain\n"
     ]
    }
   ],
   "source": [
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there are 3 keys. Each of these is a HDF group. You can think of these groups as directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- meta : Meta-data for the file\n",
    "- quality : Refers to data quality\n",
    "- strain : This is the data of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATLAB files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATLAB which is a short for Matrix Laboratory is a numerical computing environment that is an industry standard in the space of Engineering and Science. Lot of people use MATLAB and save data as **.mat** files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard library *scipy* will allow us to read or write .mat files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "mat = scipy.io.loadmat('ja_data2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data imported from matlab files is stored as dictionary in Python workspace. The mapping is as follows.\n",
    "- keys : MATLAB variable names\n",
    "- values : object assigned to variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
